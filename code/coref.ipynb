{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import *\n",
    "from string_matching_by_word import *\n",
    "from string_matching_by_spaCy_NP import *\n",
    "from word_embeddings_by_spaCy_NP import *\n",
    "from hobbs import entry\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_number = 'c3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/Users/ambuj/Documents/MS Stuff/nlp_cs_6340/final_project/nlp-project2019/dev/{}.input'.format(file_number)\n",
    "key_path = '/Users/ambuj/Documents/MS Stuff/nlp_cs_6340/final_project/nlp-project2019/dev/{}.key'.format(file_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = ReadInput(input_path)\n",
    "list_of_sentences = read.getListOfSentences()\n",
    "full_text = read.getText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sentence Dict and Cluster Head Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_dict = getSentenceDict(list_of_sentences)\n",
    "cluster_head_dict = getClusterHeads(sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for exact match by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_match_word = getCorefDict_match_word(sentence_dict, cluster_head_dict,90)\n",
    "# coref_dict_match_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for threshold match by NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_match_NP = getCorefDict_match_NP(sentence_dict, cluster_head_dict,80)\n",
    "# coref_dict_match_NP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for Word Embedding Similarity by NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# coref_dict_all_sorted = getCorefDict_all_sorted(sentence_dict, cluster_head_dict,0.5)\n",
    "# coref_dict_max_sentence = getCorefDict_max_of_each_sentence(sentence_dict, cluster_head_dict,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coref_dict_all_sorted_top3 = get_TopN_Matches(coref_dict_all_sorted,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDicts(dict1, dict2):\n",
    "    \n",
    "    d1 = dict1.copy()\n",
    "    d2 = dict2.copy()\n",
    "    \n",
    "    d1_keys = d1.keys()\n",
    "    d2_keys = d2.keys()\n",
    "    \n",
    "    for key in d1_keys:\n",
    "        d1[key] = list(map(lambda x: x[0:3], d1[key]))\n",
    "    \n",
    "    for key in d2_keys:\n",
    "        d2[key] = list(map(lambda x: x[0:3], d2[key]))\n",
    "    \n",
    "    for key in d2_keys:\n",
    "        if(key not in d1_keys):\n",
    "            d1[key] = d2[key]\n",
    "        else:\n",
    "            for val in d2[key]:\n",
    "                if(val not in d1[key]):\n",
    "                    d1[key].append(val)\n",
    "    \n",
    "    return dict(sorted(d1.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final = mergeDicts(coref_dict_match_word, coref_dict_match_NP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': [['outbreak', 8, 'outbreak'],\n",
       "  ['outbreak', 9, 'outbreak'],\n",
       "  ['outbreak', 10, 'outbreaks'],\n",
       "  ['outbreak', 10, 'outbreaks'],\n",
       "  ['outbreak', 11, 'outbreaks']],\n",
       " 'X3': [[Western Berlin, 6, 'Berlin']],\n",
       " 'X5': [[Department of Infectious Diseases, 3, 'our department'],\n",
       "  [Department of Infectious Diseases, 5, 'the Department']],\n",
       " 'X6': [['we', 3, 'we'], ['we', 5, 'we'], ['we', 11, 'We']],\n",
       " 'X7': [['virus', 4, 'virus']]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing the reference dict to Hobbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final_with_pro = entry(list_of_sentences, cluster_head_dict, coref_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': [['outbreak', 8, 'outbreak'],\n",
       "  ['outbreak', 9, 'outbreak'],\n",
       "  ['outbreak', 10, 'outbreaks'],\n",
       "  ['outbreak', 10, 'outbreaks'],\n",
       "  ['outbreak', 11, 'outbreaks']],\n",
       " 'X3': [[Western Berlin, 6, 'Berlin']],\n",
       " 'X5': [[Department of Infectious Diseases, 3, 'our department'],\n",
       "  [Department of Infectious Diseases, 5, 'the Department']],\n",
       " 'X6': [['we', 3, 'we'], ['we', 5, 'we'], ['we', 11, 'We']],\n",
       " 'X7': [['virus', 4, 'virus']],\n",
       " 'X0': [['me', 8, 'Volkmer', 0], ['me', 10, 'Volkmer', 0]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_final_with_pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding those Cluster Heads which were not predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNOPredsClusterHeads(cluster_head_dict, coref_final_with_pro):\n",
    "    for cluster_id, cluster_val in cluster_head_dict.items():\n",
    "        if(cluster_id not in coref_final_with_pro.keys()):\n",
    "            coref_final_with_pro[cluster_id] = [['',int(cluster_val[0]),'', None]]\n",
    "            \n",
    "    return coref_final_with_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final_with_pro = addNOPredsClusterHeads(cluster_head_dict, coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': [['outbreak', 8, 'outbreak'],\n",
       "  ['outbreak', 9, 'outbreak'],\n",
       "  ['outbreak', 10, 'outbreaks'],\n",
       "  ['outbreak', 10, 'outbreaks'],\n",
       "  ['outbreak', 11, 'outbreaks']],\n",
       " 'X3': [[Western Berlin, 6, 'Berlin']],\n",
       " 'X5': [[Department of Infectious Diseases, 3, 'our department'],\n",
       "  [Department of Infectious Diseases, 5, 'the Department']],\n",
       " 'X6': [['we', 3, 'we'], ['we', 5, 'we'], ['we', 11, 'We']],\n",
       " 'X7': [['virus', 4, 'virus']],\n",
       " 'X0': [['me', 8, 'Volkmer', 0], ['me', 10, 'Volkmer', 0]],\n",
       " 'X2': [['', 0, '', None]],\n",
       " 'X4': [['', 0, '', None]],\n",
       " 'X8': [['', 6, '', None]],\n",
       " 'X9': [['', 9, '', None]],\n",
       " 'X10': [['', 12, '', None]],\n",
       " 'X11': [['', 12, '', None]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_final_with_pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking only the head nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeHeadNouns(coref_final_with_pro):\n",
    "    \n",
    "    for cluster in coref_final_with_pro.keys():\n",
    "        for i in range(0, len(coref_final_with_pro[cluster])):\n",
    "            coref_final_with_pro[cluster][i][2] = coref_final_with_pro[cluster][i][2].split(' ')[-1]\n",
    "                        \n",
    "    return coref_final_with_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final_with_pro = takeHeadNouns(coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': [['outbreak', 8, 'outbreak'],\n",
       "  ['outbreak', 9, 'outbreak'],\n",
       "  ['outbreak', 10, 'outbreaks'],\n",
       "  ['outbreak', 10, 'outbreaks'],\n",
       "  ['outbreak', 11, 'outbreaks']],\n",
       " 'X3': [[Western Berlin, 6, 'Berlin']],\n",
       " 'X5': [[Department of Infectious Diseases, 3, 'department'],\n",
       "  [Department of Infectious Diseases, 5, 'Department']],\n",
       " 'X6': [['we', 3, 'we'], ['we', 5, 'we'], ['we', 11, 'We']],\n",
       " 'X7': [['virus', 4, 'virus']],\n",
       " 'X0': [['me', 8, 'Volkmer', 0], ['me', 10, 'Volkmer', 0]],\n",
       " 'X2': [['', 0, '', None]],\n",
       " 'X4': [['', 0, '', None]],\n",
       " 'X8': [['', 6, '', None]],\n",
       " 'X9': [['', 9, '', None]],\n",
       " 'X10': [['', 12, '', None]],\n",
       " 'X11': [['', 12, '', None]]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_final_with_pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printOP(cluster_head_dict, coref_final_with_pro):\n",
    "    \n",
    "    for cluster_id, cluster_head_name in cluster_head_dict.items():\n",
    "\n",
    "        print('<COREF ID=\"{}\">{}</COREF>'.format(cluster_id, cluster_head_name[1]))\n",
    "\n",
    "        coreferences = coref_final_with_pro[cluster_id]\n",
    "        list_of_sent_ids = list(map(lambda x: x[1], coreferences))\n",
    "        sorted_index_sent_ids = [i[0] for i in sorted(enumerate(list_of_sent_ids), key=lambda x:x[1])]\n",
    "        coreferences = [coreferences[i] for i in sorted_index_sent_ids]\n",
    "\n",
    "        for coref in coreferences:\n",
    "            if(coref[0] == ''):\n",
    "                continue\n",
    "            print('{{{0}}}'.format(coref[1]) + ' ' + '{' + coref[2] + '}')\n",
    "        print('\\n', end = '')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<COREF ID=\"X0\">me</COREF>\n",
      "{8} {Volkmer}\n",
      "{10} {Volkmer}\n",
      "\n",
      "<COREF ID=\"X1\">outbreak</COREF>\n",
      "{8} {outbreak}\n",
      "{9} {outbreak}\n",
      "{10} {outbreaks}\n",
      "{10} {outbreaks}\n",
      "{11} {outbreaks}\n",
      "\n",
      "<COREF ID=\"X2\">hundreds</COREF>\n",
      "\n",
      "<COREF ID=\"X3\">Western Berlin</COREF>\n",
      "{6} {Berlin}\n",
      "\n",
      "<COREF ID=\"X4\">sixties</COREF>\n",
      "\n",
      "<COREF ID=\"X5\">Department of Infectious Diseases</COREF>\n",
      "{3} {department}\n",
      "{5} {Department}\n",
      "\n",
      "<COREF ID=\"X6\">we</COREF>\n",
      "{3} {we}\n",
      "{5} {we}\n",
      "{11} {We}\n",
      "\n",
      "<COREF ID=\"X7\">virus</COREF>\n",
      "{4} {virus}\n",
      "\n",
      "<COREF ID=\"X8\">brand</COREF>\n",
      "\n",
      "<COREF ID=\"X9\">occurrences</COREF>\n",
      "\n",
      "<COREF ID=\"X10\">Mods.MPP</COREF>\n",
      "\n",
      "<COREF ID=\"X11\">JW</COREF>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "printOP(cluster_head_dict, coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}.response'.format(file_number),'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reader_o = ReadInput(key_path)\n",
    "# ans = reader_o.getListOfSentences()\n",
    "# ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
