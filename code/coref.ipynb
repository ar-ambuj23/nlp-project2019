{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import *\n",
    "from string_matching_by_word import *\n",
    "from string_matching_by_spaCy_NP import *\n",
    "from word_embeddings_by_spaCy_NP import *\n",
    "from hobbs import entry\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_number = 'c5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/Users/ambuj/Documents/MS Stuff/nlp_cs_6340/final_project/nlp-project2019/dev/{}.input'.format(file_number)\n",
    "key_path = '/Users/ambuj/Documents/MS Stuff/nlp_cs_6340/final_project/nlp-project2019/dev/{}.key'.format(file_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = ReadInput(input_path)\n",
    "list_of_sentences = read.getListOfSentences()\n",
    "full_text = read.getText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sentence Dict and Cluster Head Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_dict = getSentenceDict(list_of_sentences)\n",
    "cluster_head_dict = getClusterHeads(sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for exact match by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_match_word = getCorefDict_match_word(sentence_dict, cluster_head_dict,90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for threshold match by NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_match_NP = getCorefDict_match_NP(sentence_dict, cluster_head_dict,80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for Word Embedding Similarity by NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coref_dict_all_sorted = getCorefDict_all_sorted(sentence_dict, cluster_head_dict,0.5)\n",
    "# coref_dict_max_sentence = getCorefDict_max_of_each_sentence(sentence_dict, cluster_head_dict,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_all_sorted_top3 = get_TopN_Matches(coref_dict_all_sorted,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging coref_dict_match_NP with coref_dict_all_sorted_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDicts(string_matching_dict, word_embedding_dict):\n",
    "    \n",
    "    d1 = string_matching_dict.copy()\n",
    "    d2 = word_embedding_dict.copy()\n",
    "    \n",
    "    d1_keys = d1.keys()\n",
    "    d2_keys = d2.keys()\n",
    "    \n",
    "    for key in d1_keys:\n",
    "        d1[key] = list(map(lambda x: x[0:3], d1[key]))\n",
    "    \n",
    "    for key in d2_keys:\n",
    "        d2[key] = list(map(lambda x: x[0:3], d2[key]))\n",
    "    \n",
    "    for key in d2_keys:\n",
    "        if(key not in d1_keys):\n",
    "            d1[key] = d2[key]\n",
    "        else:\n",
    "            for val in d2[key]:\n",
    "                if(val not in d1[key]):\n",
    "                    d1[key].append(val)\n",
    "    \n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final = mergeDicts(coref_dict_match_NP, coref_dict_all_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coref_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing the reference dict to Hobbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final_with_pro = entry(list_of_sentences, cluster_head_dict, coref_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coref_final_with_pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding those Cluster Heads which were not predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNOPredsClusterHeads(cluster_head_dict, coref_final_with_pro):\n",
    "    for cluster_id, cluster_val in cluster_head_dict.items():\n",
    "        if(cluster_id not in coref_final_with_pro.keys()):\n",
    "            coref_final_with_pro[cluster_id] = [['',int(cluster_val[0]),'', None]]\n",
    "            \n",
    "    return coref_final_with_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final_with_pro = addNOPredsClusterHeads(cluster_head_dict, coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the Determiners from the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDetfromStart(coref_final_with_pro):\n",
    "    for cluster in coref_final_with_pro.keys():\n",
    "        for i in range(0, len(coref_final_with_pro[cluster])):\n",
    "            if(len(coref_final_with_pro[cluster][i][2].split(' '))>1):\n",
    "                ref_word_list = coref_final_with_pro[cluster][i][2].strip().split(' ')\n",
    "                ref_word_list = list(filter(bool, ref_word_list) )\n",
    "                check = pos_tag(ref_word_list)\n",
    "                if len(check) >1:\n",
    "                    if 'DT' in check[0][1]:\n",
    "                        sentence = ' '.join(coref_final_with_pro[cluster][i][2].split(' ')[1:])\n",
    "                        coref_final_with_pro[cluster][i][2] = ' '.join(coref_final_with_pro[cluster][i][2].split(' ')[1:])\n",
    "                        \n",
    "    return coref_final_with_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final_with_pro = removeDetfromStart(coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making no predictions for Pronouns (will be included in final version - Reverse Hobb's/ Trained Word Embedding model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def removePredsforPronouns(coref_final_with_pro):\n",
    "    for cluster in coref_final_with_pro.keys():\n",
    "        for i in range(0, len(coref_final_with_pro[cluster])):\n",
    "            curr_cluster_name = coref_final_with_pro[cluster][i][0].split(' ')\n",
    "            if(len(curr_cluster_name)==1 and curr_cluster_name[0]!=''):\n",
    "                if('PRP' in pos_tag(curr_cluster_name)[0]):\n",
    "                    coref_final_with_pro[cluster] = []\n",
    "                    break\n",
    "    return coref_final_with_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final_with_pro = removePredsforPronouns(coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printOP(cluster_head_dict, coref_final_with_pro):\n",
    "    \n",
    "    for cluster_id, cluster_head_name in cluster_head_dict.items():\n",
    "\n",
    "        print('<COREF ID=\"{}\">{}</COREF>'.format(cluster_id, cluster_head_name[1]))\n",
    "\n",
    "        coreferences = coref_final_with_pro[cluster_id]\n",
    "        list_of_sent_ids = list(map(lambda x: x[1], coreferences))\n",
    "        sorted_index_sent_ids = [i[0] for i in sorted(enumerate(list_of_sent_ids), key=lambda x:x[1])]\n",
    "        coreferences = [coreferences[i] for i in sorted_index_sent_ids]\n",
    "\n",
    "        for coref in coreferences:\n",
    "            if(coref[0] == ''):\n",
    "                continue\n",
    "            print('{{{0}}}'.format(coref[1]) + ' ' + '{' + coref[2] + '}')\n",
    "        print('\\n', end = '')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "printOP(cluster_head_dict, coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}.response'.format(file_number),'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reader_o = ReadInput(key_path)\n",
    "# ans = reader_o.getListOfSentences()\n",
    "# ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
