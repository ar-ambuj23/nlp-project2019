{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import *\n",
    "from string_matching_by_word import *\n",
    "from string_matching_by_spaCy_NP import *\n",
    "from word_embeddings_by_spaCy_NP import *\n",
    "from hobbs import entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/Users/Barretts Laptop/Documents/GitHub/nlp-project2019/dev/b3.input'\n",
    "key_path = '/Users/Barretts Laptop/Documents/GitHub/nlp-project2019/dev/b3.key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = ReadInput(input_path)\n",
    "list_of_sentences = read.getListOfSentences()\n",
    "full_text = read.getText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sentence Dict and Cluster Head Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_dict = getSentenceDict(list_of_sentences)\n",
    "cluster_head_dict = getClusterHeads(sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for exact match by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_match_word = getCorefDict_match_word(sentence_dict, cluster_head_dict,90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for threshold match by NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_match_NP = getCorefDict_match_NP(sentence_dict, cluster_head_dict,80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for Word Embedding Similarity by NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coref_dict_all_sorted = getCorefDict_all_sorted(sentence_dict, cluster_head_dict,0.5)\n",
    "coref_dict_max_sentence = getCorefDict_max_of_each_sentence(sentence_dict, cluster_head_dict,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_all_sorted_top3 = get_TopN_Matches(coref_dict_all_sorted,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging coref_dict_match_NP with coref_dict_all_sorted_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDicts(d1, d2):\n",
    "    \n",
    "    d1_keys = d1.keys()\n",
    "    d2_keys = d2.keys()\n",
    "    \n",
    "    d_keys = list(set(d1_keys).union(set(d2_keys)))\n",
    "    d = {}\n",
    "    \n",
    "    for key in d_keys:\n",
    "\n",
    "        d1_val = []\n",
    "        d2_val = []\n",
    "        \n",
    "        if(key in d1_keys):\n",
    "            d1_val = set(tuple(i) for i in d1[key])\n",
    "        if(key in d2_keys):\n",
    "            d2_val = set(tuple(i) for i in d2[key])\n",
    "            \n",
    "        if(len(d1_val)!= 0 and len(d2_val)!= 0):\n",
    "            d[key] = list(d1_val.union(d2_val))\n",
    "            d[key] = [list(i) for i in d[key]]\n",
    "        elif(len(d1_val)== 0 and len(d2_val)!= 0):\n",
    "            d[key] = d2[key]\n",
    "        elif(len(d1_val)!= 0 and len(d2_val)== 0):\n",
    "            d[key] = d1[key]\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final = mergeDicts(coref_dict_match_NP, coref_dict_all_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing the reference dict to Hobbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'X9'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-b4f9cffcfca3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcoref_final_with_pro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_head_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoref_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\nlp-project2019\\code\\hobbs.py\u001b[0m in \u001b[0;36mentry\u001b[1;34m(file_lines, cluster_head_dict, reference_dict)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<COREF .+?>.+?<.+?>'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<.+?>'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mhobbs_alg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreference_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\nlp-project2019\\code\\hobbs.py\u001b[0m in \u001b[0;36mhobbs_alg\u001b[1;34m(string, num, reference_dict)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;31m#   Creates and populates the headnoun dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;31m#   find_coref()   Should be called once at the start of the pronoun search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mfind_possible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibilities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\nlp-project2019\\code\\hobbs.py\u001b[0m in \u001b[0;36mfind_possible\u001b[1;34m(possibilities, num, reference_dict)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;31m#   Print the most likely head for the pronoun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[0mreference_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpronoun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m             \u001b[0mhead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_coref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpronoun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'X9'"
     ]
    }
   ],
   "source": [
    "coref_final_with_pro = entry(list_of_sentences, cluster_head_dict, coref_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coref_final_with_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id, cluster_val in cluster_head_dict.items():\n",
    "    if(cluster_id not in coref_final_with_pro.keys()):\n",
    "        coref_final_with_pro[cluster_id] = [['',int(cluster_val[0]),'', None]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printOP(cluster_head_dict, coref_final_with_pro):\n",
    "    \n",
    "    for cluster_id, cluster_head_name in cluster_head_dict.items():\n",
    "\n",
    "        print('<COREF ID=\"{}\">{}</COREF>'.format(cluster_id, cluster_head_name[1]))\n",
    "\n",
    "        coreferences = coref_final_with_pro[cluster_id]\n",
    "        list_of_sent_ids = list(map(lambda x: x[1], coreferences))\n",
    "        sorted_index_sent_ids = [i[0] for i in sorted(enumerate(list_of_sent_ids), key=lambda x:x[1])]\n",
    "        coreferences = [coreferences[i] for i in sorted_index_sent_ids]\n",
    "\n",
    "        for coref in coreferences:\n",
    "            if(coref[0] == ''):\n",
    "                continue\n",
    "            print('{{{0}}}'.format(coref[1]) + ' ' + '{' + coref[2] + '}')\n",
    "        print('\\n', end = '')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "printOP(cluster_head_dict, coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('b3.response','w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reader_o = ReadInput(key_path)\n",
    "# ans = reader_o.getListOfSentences()\n",
    "# ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
