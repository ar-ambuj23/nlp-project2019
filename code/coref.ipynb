{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import *\n",
    "from string_matching_by_word import *\n",
    "from string_matching_by_spaCy_NP import *\n",
    "from word_embeddings_by_spaCy_NP import *\n",
    "from hobbs import entry\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/Users/ambuj/Documents/MS Stuff/nlp_cs_6340/final_project/nlp-project2019/dev/a8.input'\n",
    "key_path = '/Users/ambuj/Documents/MS Stuff/nlp_cs_6340/final_project/nlp-project2019/dev/a8.key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = ReadInput(input_path)\n",
    "list_of_sentences = read.getListOfSentences()\n",
    "full_text = read.getText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sentence Dict and Cluster Head Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_dict = getSentenceDict(list_of_sentences)\n",
    "cluster_head_dict = getClusterHeads(sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for exact match by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_match_word = getCorefDict_match_word(sentence_dict, cluster_head_dict,90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for threshold match by NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_match_NP = getCorefDict_match_NP(sentence_dict, cluster_head_dict,80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for Word Embedding Similarity by NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coref_dict_all_sorted = getCorefDict_all_sorted(sentence_dict, cluster_head_dict,0.5)\n",
    "# coref_dict_max_sentence = getCorefDict_max_of_each_sentence(sentence_dict, cluster_head_dict,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_all_sorted_top3 = get_TopN_Matches(coref_dict_all_sorted,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging coref_dict_match_NP with coref_dict_all_sorted_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDicts(string_matching_dict, word_embedding_dict):\n",
    "    \n",
    "    d1 = string_matching_dict.copy()\n",
    "    d2 = word_embedding_dict.copy()\n",
    "    \n",
    "    d1_keys = d1.keys()\n",
    "    d2_keys = d2.keys()\n",
    "    \n",
    "    for key in d1_keys:\n",
    "        d1[key] = list(map(lambda x: x[0:3], d1[key]))\n",
    "    \n",
    "    for key in d2_keys:\n",
    "        d2[key] = list(map(lambda x: x[0:3], d2[key]))\n",
    "    \n",
    "    for key in d2_keys:\n",
    "        if(key not in d1_keys):\n",
    "            d1[key] = d2[key]\n",
    "        else:\n",
    "            for val in d2[key]:\n",
    "                if(val not in d1[key]):\n",
    "                    d1[key].append(val)\n",
    "    \n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final = mergeDicts(coref_dict_match_NP, coref_dict_all_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coref_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing the reference dict to Hobbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    }
   ],
   "source": [
    "coref_final_with_pro = entry(list_of_sentences, cluster_head_dict, coref_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coref_final_with_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id, cluster_val in cluster_head_dict.items():\n",
    "    if(cluster_id not in coref_final_with_pro.keys()):\n",
    "        coref_final_with_pro[cluster_id] = [['',int(cluster_val[0]),'', None]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the Determiners from the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in coref_final_with_pro.keys():\n",
    "    for i in range(0, len(coref_final_with_pro[cluster])):\n",
    "        if(len(coref_final_with_pro[cluster][i][2].split(' '))>1):\n",
    "            ref_word_list = coref_final_with_pro[cluster][i][2].strip().split(' ')\n",
    "            check = pos_tag(ref_word_list)\n",
    "            if len(check) >1:\n",
    "                if 'DT' in check[0][1]:\n",
    "                    sentence = ' '.join(coref_final_with_pro[cluster][i][2].split(' ')[1:])\n",
    "                    coref_final_with_pro[cluster][i][2] = ' '.join(coref_final_with_pro[cluster][i][2].split(' ')[1:])\n",
    "                    #print(coref_final_with_pro[cluster][i])\n",
    "# coref_final_with_pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printOP(cluster_head_dict, coref_final_with_pro):\n",
    "    \n",
    "    for cluster_id, cluster_head_name in cluster_head_dict.items():\n",
    "\n",
    "        print('<COREF ID=\"{}\">{}</COREF>'.format(cluster_id, cluster_head_name[1]))\n",
    "\n",
    "        coreferences = coref_final_with_pro[cluster_id]\n",
    "        list_of_sent_ids = list(map(lambda x: x[1], coreferences))\n",
    "        sorted_index_sent_ids = [i[0] for i in sorted(enumerate(list_of_sent_ids), key=lambda x:x[1])]\n",
    "        coreferences = [coreferences[i] for i in sorted_index_sent_ids]\n",
    "\n",
    "        for coref in coreferences:\n",
    "            if(coref[0] == ''):\n",
    "                continue\n",
    "            print('{{{0}}}'.format(coref[1]) + ' ' + '{' + coref[2] + '}')\n",
    "        print('\\n', end = '')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "printOP(cluster_head_dict, coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('a8.response','w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reader_o = ReadInput(key_path)\n",
    "# ans = reader_o.getListOfSentences()\n",
    "# ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
