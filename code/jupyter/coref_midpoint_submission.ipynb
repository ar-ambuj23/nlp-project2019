{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import *\n",
    "from string_matching_by_word import *\n",
    "from string_matching_by_spaCy_NP import *\n",
    "from word_embeddings_by_spaCy_NP import *\n",
    "from hobbs import entry\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_number = 'c17'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/Users/ambuj/Documents/MS Stuff/nlp_cs_6340/final_project/nlp-project2019/dev/{}.input'.format(file_number)\n",
    "key_path = '/Users/ambuj/Documents/MS Stuff/nlp_cs_6340/final_project/nlp-project2019/dev/{}.key'.format(file_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = ReadInput(input_path)\n",
    "list_of_sentences = read.getListOfSentences()\n",
    "full_text = read.getText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sentence Dict and Cluster Head Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_dict = getSentenceDict(list_of_sentences)\n",
    "cluster_head_dict = getClusterHeads(sentence_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X0': [0, 'ProMED'],\n",
       " 'X1': [0, 'posting'],\n",
       " 'X2': [0, 'Psittacosis'],\n",
       " 'X3': [0, 'one significant misleading fact and a few questionable elements'],\n",
       " 'X4': [1, 'I'],\n",
       " 'X5': [1, 'the source'],\n",
       " 'X6': [3, 'transmission'],\n",
       " 'X7': [8, 'species'],\n",
       " 'X8': [10, 'some'],\n",
       " 'X9': [12, 'the organism'],\n",
       " 'X10': [13, 'time']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_head_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for exact match by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_match_word = getCorefDict_match_word(sentence_dict, cluster_head_dict,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X0': [['ProMED', 15, 'ProMED', 100]],\n",
       " 'X2': [['Psittacosis', 5, 'psittacosis', 100],\n",
       "  ['Psittacosis', 16, 'psittacosis', 100]],\n",
       " 'X4': [['I', 9, 'I', 100]],\n",
       " 'X6': [['transmission', 5, 'transmission', 100],\n",
       "  ['transmission', 8, 'transmission', 100],\n",
       "  ['transmission', 19, 'transmission', 100]],\n",
       " 'X7': [['species', 10, 'species', 100],\n",
       "  ['species', 11, 'species', 100],\n",
       "  ['species', 12, 'species', 100]],\n",
       " 'X8': [['some', 11, 'some', 100]]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_dict_match_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for threshold match by NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_match_NP = getCorefDict_match_NP(sentence_dict, cluster_head_dict,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': [['posting', 14, 'disease reporting', 86]],\n",
       " 'X2': [['Psittacosis', 5, 'psittacosis', 100],\n",
       "  ['Psittacosis', 16, 'psittacosis', 100],\n",
       "  ['Psittacosis', 19, 'psittacines', 82]],\n",
       " 'X3': [['one significant misleading fact and a few questionable elements',\n",
       "   14,\n",
       "   'significance',\n",
       "   83]],\n",
       " 'X4': [['I', 1, 'this report', 100],\n",
       "  ['I', 2, 'the disease', 100],\n",
       "  ['I', 3, 'the organisms', 100],\n",
       "  ['I', 4, 'the disease', 100],\n",
       "  ['I', 4, 'the 1943 Louisiana outbreak', 100],\n",
       "  ['I', 4, 'a single fatal human case', 100],\n",
       "  ['I', 4, 'rise', 100],\n",
       "  ['I', 4, '18 additional human cases', 100],\n",
       "  ['I', 4, 'nursing attendants', 100],\n",
       "  ['I', 4, 'the hospital', 100],\n",
       "  ['I', 5, 'Interhuman transmission', 100],\n",
       "  ['I', 5, 'psittacosis', 100],\n",
       "  ['I', 6, 'the Danish Med Bul', 100],\n",
       "  ['I', 8, '*experimental* hosts', 100],\n",
       "  ['I', 8, 'this disease', 100],\n",
       "  ['I', 8, 'birds', 100],\n",
       "  ['I', 8, 'experimental disease transmission', 100],\n",
       "  ['I', 8, 'the disease', 100],\n",
       "  ['I', 9, 'the claim', 100],\n",
       "  ['I', 9, 'all birds', 100],\n",
       "  ['I', 9, 'the infection', 100],\n",
       "  ['I', 10, 'different species', 100],\n",
       "  ['I', 10, 'birds', 100],\n",
       "  ['I', 10, 'the disease', 100],\n",
       "  ['I', 11, 'some species', 100],\n",
       "  ['I', 11, 'birds', 100],\n",
       "  ['I', 11, 'the disease', 100],\n",
       "  ['I', 12, 'Highly resistant species', 100],\n",
       "  ['I', 12, 'birds', 100],\n",
       "  ['I', 12, 'the same human health risk', 100],\n",
       "  ['I', 12, 'these bacteria', 100],\n",
       "  ['I', 13, 'the article', 100],\n",
       "  ['I', 13, 'longer incubation periods', 100],\n",
       "  ['I', 13, 'the literature', 100],\n",
       "  ['I', 14, 'an open mind', 100],\n",
       "  ['I', 14, 'disease reporting', 100],\n",
       "  ['I', 14, 'the disease', 100],\n",
       "  ['I', 14, 'significance', 100],\n",
       "  ['I', 15, 'these clarifications', 100],\n",
       "  ['I', 16, 'a pandemic', 100],\n",
       "  ['I', 16, 'psittacosis', 100],\n",
       "  ['I', 16, '12 countries', 100],\n",
       "  ['I', 18, 'Diseases', 100],\n",
       "  ['I', 18, 'animals', 100],\n",
       "  ['I', 18, 'Springfield IL', 100],\n",
       "  ['I', 19, 'the importation', 100],\n",
       "  ['I', 19, 'psittacines', 100],\n",
       "  ['I', 19, 'South America', 100],\n",
       "  ['I', 19, 'human- to-human transmission', 100],\n",
       "  ['I', 21, 'the human disease', 100]],\n",
       " 'X5': [['the source', 14, 'the source', 100]],\n",
       " 'X6': [['transmission', 5, 'Interhuman transmission', 100],\n",
       "  ['transmission', 8, 'experimental disease transmission', 100],\n",
       "  ['transmission', 19, 'human- to-human transmission', 100]],\n",
       " 'X7': [['species', 10, 'different species', 100],\n",
       "  ['species', 11, 'some species', 100],\n",
       "  ['species', 12, 'Highly resistant species', 100]],\n",
       " 'X8': [['some', 11, 'some species', 100]]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_dict_match_NP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Coref for Word Embedding Similarity by NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coref_dict_all_sorted = getCorefDict_all_sorted(sentence_dict, cluster_head_dict,0.5)\n",
    "# coref_dict_max_sentence = getCorefDict_max_of_each_sentence(sentence_dict, cluster_head_dict,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dict_all_sorted_top3 = get_TopN_Matches(coref_dict_all_sorted,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X0': [['ProMED', 15, 'ProMED', 1.0]],\n",
       " 'X1': [['posting', 13, 'the article', 0.5097392858649753],\n",
       "  ['posting', 15, 'these clarifications', 0.5083162151332226],\n",
       "  ['posting', 1, 'this report', 0.5011811292796158]],\n",
       " 'X3': [['one significant misleading fact and a few questionable elements',\n",
       "   1,\n",
       "   'the less accurate elements',\n",
       "   0.8440262128852485],\n",
       "  ['one significant misleading fact and a few questionable elements',\n",
       "   12,\n",
       "   'only a small number',\n",
       "   0.81341919379224],\n",
       "  ['one significant misleading fact and a few questionable elements',\n",
       "   12,\n",
       "   'the same human health risk',\n",
       "   0.7770392092436001]],\n",
       " 'X4': [['I', 6, 'the Danish Med Bul', 0.5531277435834586],\n",
       "  ['I', 22, 'Mod.JW', 0.515430350311912]],\n",
       " 'X5': [['the source', 14, 'the source', 1.0],\n",
       "  ['the source', 13, 'the article', 0.7295915468779361],\n",
       "  ['the source', 9, 'the claim', 0.7011473842206236]],\n",
       " 'X6': [['transmission', 5, 'Interhuman transmission', 0.9999999728175678],\n",
       "  ['transmission', 8, 'experimental disease transmission', 0.7246828270590566],\n",
       "  ['transmission', 19, 'human- to-human transmission', 0.6732381880421119]],\n",
       " 'X7': [['species', 10, 'different species', 0.9037001555528884],\n",
       "  ['species', 11, 'some species', 0.8952235078201297],\n",
       "  ['species', 12, 'Highly resistant species', 0.7670661285070787]],\n",
       " 'X8': [['some', 12, 'only a small number', 0.7132729321316051],\n",
       "  ['some', 15, 'these clarifications', 0.7056471680332387],\n",
       "  ['some', 11, 'some species', 0.700500979366273]],\n",
       " 'X9': [['the organism', 21, 'the human disease', 0.7473873317902746],\n",
       "  ['the organism', 14, 'the disease', 0.6944018717028148],\n",
       "  ['the organism', 12, 'the same human health risk', 0.691785089700013]],\n",
       " 'X10': [['time', 13, 'up to 4 weeks', 0.6474018106731876],\n",
       "  ['time', 13, 'longer incubation periods', 0.6123035380600677],\n",
       "  ['time', 14, 'an open mind', 0.6020120272672634]]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_dict_all_sorted_top3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging coref_dict_match_NP with coref_dict_all_sorted_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDicts(string_matching_dict, word_embedding_dict):\n",
    "    \n",
    "    d1 = string_matching_dict.copy()\n",
    "    d2 = word_embedding_dict.copy()\n",
    "    \n",
    "    d1_keys = d1.keys()\n",
    "    d2_keys = d2.keys()\n",
    "    \n",
    "    for key in d1_keys:\n",
    "        d1[key] = list(map(lambda x: x[0:3], d1[key]))\n",
    "    \n",
    "    for key in d2_keys:\n",
    "        d2[key] = list(map(lambda x: x[0:3], d2[key]))\n",
    "    \n",
    "    for key in d2_keys:\n",
    "        if(key not in d1_keys):\n",
    "            d1[key] = d2[key]\n",
    "        else:\n",
    "            for val in d2[key]:\n",
    "                if(val not in d1[key]):\n",
    "                    d1[key].append(val)\n",
    "    \n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final = mergeDicts(coref_dict_match_NP, coref_dict_all_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coref_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing the reference dict to Hobbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final_with_pro = entry(list_of_sentences, cluster_head_dict, coref_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coref_final_with_pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding those Cluster Heads which were not predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNOPredsClusterHeads(cluster_head_dict, coref_final_with_pro):\n",
    "    for cluster_id, cluster_val in cluster_head_dict.items():\n",
    "        if(cluster_id not in coref_final_with_pro.keys()):\n",
    "            coref_final_with_pro[cluster_id] = [['',int(cluster_val[0]),'', None]]\n",
    "            \n",
    "    return coref_final_with_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final_with_pro = addNOPredsClusterHeads(cluster_head_dict, coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the Determiners from the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDetfromStart(coref_final_with_pro):\n",
    "    for cluster in coref_final_with_pro.keys():\n",
    "        for i in range(0, len(coref_final_with_pro[cluster])):\n",
    "            if(len(coref_final_with_pro[cluster][i][2].split(' '))>1):\n",
    "                ref_word_list = coref_final_with_pro[cluster][i][2].strip().split(' ')\n",
    "                ref_word_list = list(filter(bool, ref_word_list) )\n",
    "                check = pos_tag(ref_word_list)\n",
    "                if len(check) >1:\n",
    "                    if 'DT' in check[0][1]:\n",
    "                        sentence = ' '.join(coref_final_with_pro[cluster][i][2].split(' ')[1:])\n",
    "                        coref_final_with_pro[cluster][i][2] = ' '.join(coref_final_with_pro[cluster][i][2].split(' ')[1:])\n",
    "                        \n",
    "    return coref_final_with_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final_with_pro = removeDetfromStart(coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making no predictions for Pronouns (will be included in final version - Reverse Hobb's/ Trained Word Embedding model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def removePredsforPronouns(coref_final_with_pro):\n",
    "    for cluster in coref_final_with_pro.keys():\n",
    "        for i in range(0, len(coref_final_with_pro[cluster])):\n",
    "            curr_cluster_name = coref_final_with_pro[cluster][i][0].split(' ')\n",
    "            if(len(curr_cluster_name)==1 and curr_cluster_name[0]!=''):\n",
    "                if('PRP' in pos_tag(curr_cluster_name)[0]):\n",
    "                    coref_final_with_pro[cluster] = []\n",
    "                    break\n",
    "    return coref_final_with_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_final_with_pro = removePredsforPronouns(coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printOP(cluster_head_dict, coref_final_with_pro):\n",
    "    \n",
    "    for cluster_id, cluster_head_name in cluster_head_dict.items():\n",
    "\n",
    "        print('<COREF ID=\"{}\">{}</COREF>'.format(cluster_id, cluster_head_name[1]))\n",
    "\n",
    "        coreferences = coref_final_with_pro[cluster_id]\n",
    "        list_of_sent_ids = list(map(lambda x: x[1], coreferences))\n",
    "        sorted_index_sent_ids = [i[0] for i in sorted(enumerate(list_of_sent_ids), key=lambda x:x[1])]\n",
    "        coreferences = [coreferences[i] for i in sorted_index_sent_ids]\n",
    "\n",
    "        for coref in coreferences:\n",
    "            if(coref[0] == ''):\n",
    "                continue\n",
    "            print('{{{0}}}'.format(coref[1]) + ' ' + '{' + coref[2] + '}')\n",
    "        print('\\n', end = '')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "printOP(cluster_head_dict, coref_final_with_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}.response'.format(file_number),'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reader_o = ReadInput(key_path)\n",
    "# ans = reader_o.getListOfSentences()\n",
    "# ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
